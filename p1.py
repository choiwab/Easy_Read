# ì—¬ê¸°ì„œë¶€í„° ì„¸ì¤„ì€ ë¡œì»¬í™˜ê²½ì—ì„œ ëŒë¦´ ë•Œì—ëŠ”(ì¦‰ ì›¹ì‚¬ì´íŠ¸ë¡œ ë°°í¬ ì•ˆí•˜ê³  ê·¸ëƒ¥ í„°ë¯¸ë„ì—ì„œ ëŒë¦´ë•Œ) ì£¼ì„ì²˜ë¦¬ í•´ì£¼ì…”ì•¼í•©ë‹ˆë‹¤. 
# ë°°í¬í• ë•Œì—ëŠ” ì£¼ì„ì²˜ë¦¬í•˜ì‹œë©´ ì•ˆë©ë‹ˆë‹¤. 
# ì£¼ì„ì²˜ë¦¬ ë°©ë²•ì€ "Ctrl + "/"" ëˆ„ë¥´ê¸°
# ---------------------------------------------------
__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
# ---------------------------------------------------

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
import streamlit as st
import time
import os

from langchain.chains import LLMChain
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.utilities.dalle_image_generator import DallEAPIWrapper

from bs4 import BeautifulSoup
import validators  # To validate URL
import requests
from pypdf import PdfReader 

# import nltk
# #nltk.download()
# nltk.download('punkt')
# from nltk.tokenize import sent_tokenize


llm = OpenAI(temperature=0.9)
prompt = PromptTemplate(
    input_variables=["image_desc"],
    template="Generate a concise prompt to generate an image based on the following description and make sure to include a instruction to not include text in the image: {image_desc}",
)
chain = LLMChain(llm=llm, prompt=prompt)


#ë¡œì»¬ í™˜ê²½ì—ì„œ ë‚´ api keyë¡œ ëŒë¦´ë•Œ 
# ---------------------------------------------------
#os.environ["OPENAI_API_KEY"] ="" 
# ---------------------------------------------------

#ì²«ë²ˆì§¸ êµ¬í˜„ ë°©ë²•: Streamlit ë°°í¬í• ë•Œ OpenAI API keyë¡œ ëŒë ¤ë„ ëœë‹¤ë©´ ë‹¤ìŒ ì½”ë“œë¡œ ë°°í¬í•˜ê¸°
#ëŒ€ì‹  streamlitì—ì„œ ë”°ë¡œ api keyë¥¼ ì¶”ê°€í•´ì•¼í•©ë‹ˆë‹¤.
#---------------------------------------------------
# os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
#---------------------------------------------------

# ë‘ë²ˆì§¸ êµ¬í˜„ ë°©ë²•: ì‚¬ìš©ìì˜ api key ë°›ì•„ì„œ ëŒë¦¬ê¸°
# ---------------------------------------------------
openai_api_key = st.sidebar.text_input("OpenAI API Key", type="password")

if not openai_api_key:
    st.info("OpenAI APIë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
    st.stop()

import os
os.environ["OPENAI_API_KEY"] = openai_api_key
# ---------------------------------------------------


# temperatureëŠ” 0ì— ê°€ê¹Œì›Œì§ˆìˆ˜ë¡ í˜•ì‹ì ì¸ ë‹µë³€ì„ ë‚´ë±‰ê³ , 1ì— ê°€ê¹Œì›Œì§ˆìˆ˜ë¡ ì°½ì˜ì ì¸ ë‹µë³€ì„ ë‚´ë±‰ìŒ
llm = ChatOpenAI(temperature=0.2, model="gpt-3.5-turbo-1106")

# ì–´ë–¤ íŒŒì¼ì„ í•™ìŠµì‹œí‚¤ëŠ”ì§€ì— ë”°ë¼ ì½”ë“œë¥¼ ë°”ê¿”ì£¼ì„¸ìš”. ex) pdf, html, csv

# ì²«ë²ˆì§¸ êµ¬í˜„ ë°©ë²•: ì›¹ì‚¬ì´íŠ¸ url í•™ìŠµì‹œí‚¤ê¸°
# ---------------------------------------------------
# from langchain.document_loaders import WebBaseLoader

# loader = WebBaseLoader("https://sosoeasyword.com/27/?q=YToxOntzOjEyOiJrZXl3b3JkX3R5cGUiO3M6MzoiYWxsIjt9&bmode=view&idx=17122350&t=board")
# data = loader.load()
# ---------------------------------------------------


# ë‘ë²ˆì§¸ êµ¬í˜„ ë°©ë²•: pdf í•™ìŠµì‹œí‚¤ê¸°
# ë¨¼ì € VSCodeì—ì„œ ë§Œë“  ì´ í´ë” ë‚´ì— pdf íŒŒì¼ì„ ì—…ë¡œë“œ í•´ì£¼ì…”ì•¼í•´ìš”!
# ì‚¬ìš©í•˜ê³  ì‹¶ìœ¼ë©´ ì•„ë˜ ë¶€ë¶„ì˜ ì½”ë“œ ì£¼ì„ì„ ì—†ì• ì£¼ì„¸ìš”
# ---------------------------------------------------
# from langchain.document_loaders import PyPDFLoader

# loader = PyPDFLoader("íŒŒì¼ì´ë¦„.pdf")
# pages = loader.load_and_split()

# data = []
# for content in pages:
#     data.append(content)
# ---------------------------------------------------


# ì„¸ë²ˆì§¸ êµ¬í˜„ ë°©ë²•: csv í•™ìŠµì‹œí‚¤ê¸°
# ë¨¼ì € VSCodeì—ì„œ ë§Œë“  ì´ í´ë” ë‚´ì— csv íŒŒì¼ì„ ì—…ë¡œë“œ í•´ì£¼ì…”ì•¼í•´ìš”!
# ì‚¬ìš©í•˜ê³  ì‹¶ìœ¼ë©´ ì•„ë˜ ë¶€ë¶„ì˜ ì½”ë“œ ì£¼ì„ì„ ì—†ì• ì£¼ì„¸ìš”
# ---------------------------------------------------
from langchain.document_loaders.csv_loader import CSVLoader

loader = CSVLoader(file_path= 'instructions.csv')
data = loader.load()
print(data)
# ---------------------------------------------------

# ì˜¬ë¦° íŒŒì¼ ë‚´ìš© ìª¼ê°œê¸°
text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 0)
all_splits = text_splitter.split_documents(data)

# ìª¼ê°  ë‚´ìš© vectorstore ë°ì´í„°ë² ì´ìŠ¤ì— ì—…ë¡œë“œí•˜ê¸°
vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())

# ë°ì´í„°ë² ì´ìŠ¤ì— ì—…ë¡œë“œ í•œ ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë„ë¡ ì…‹ì—…
retriever = vectorstore.as_retriever()

# ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©í•  ë‚´ìš© ë¶ˆëŸ¬ì˜¤ëŠ” íˆ´ ë§Œë“¤ê¸°
from langchain.agents.agent_toolkits import create_retriever_tool

tool = create_retriever_tool(
    retriever,
    "cusomter_service",
    "Searches and returns documents regarding the customer service guide.",
)
tools = [tool]

# ëŒ€í™” ë‚´ìš© ê¸°ë¡í•˜ëŠ” ë©”ëª¨ë¦¬ ë³€ìˆ˜ ì…‹ì—…
memory_key = "history"

from langchain.agents.openai_functions_agent.agent_token_buffer_memory import (
    AgentTokenBufferMemory,
)

memory = AgentTokenBufferMemory(memory_key=memory_key, llm=llm)

from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent
from langchain.schema.messages import SystemMessage
from langchain.prompts import MessagesPlaceholder

# AI ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©í•  í”„ë¡¬í”„íŠ¸ ì§œì£¼ê¸°
system_message = SystemMessage(
    content=(
       # "You are service agent that converts complex reading material into easy read material for mentally disabled people"
        "You are service agent for mentally disabled people"
        "If you are given a complex reading material, you will convert it easy read material."
        "If you are asked a question, you will answer in a simple manner."
        "Do your best to convert the reading material into the most simple terms"
        "Look up for the example using the tools you have"
        "Follow these rules: "  
        "1. Write in short sentences of 15-20 words"
        "2. Skip a line for each sentence"
        "3. Write as if you are speaking."
        "4. Each sentence has one idea."
        "5. Use active verbs as much as possible."
        "6. Keep the language personal e.g. you, we "
        "7. Use drop down bullet points to list."
        "8. Reduce punctuation as much as you can."
       #"Make sure to answer in Korean."
    )
)

prompt = OpenAIFunctionsAgent.create_prompt(
    system_message=system_message,
    extra_prompt_messages=[MessagesPlaceholder(variable_name=memory_key)],
)

# ì—ì´ì „íŠ¸ ì…‹ì—…í•´ì£¼ê¸°
agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt)

from langchain.agents import AgentExecutor

# ìœ„ì—ì„œ ë§Œë“  íˆ´, í”„ë¡¬í”„íŠ¸ë¥¼ í† ëŒ€ë¡œ ì—ì´ì „íŠ¸ ì‹¤í–‰ì‹œì¼œì£¼ê¸° ìœ„í•´ ì…‹ì—…
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    memory=memory,
    verbose=True,
    return_intermediate_steps=True,
)

# Function to scrape text from a URL
def scrape_text_from_url(url):
    try:
        print("111")
        response = requests.get(url)
        print("111111")
        if response.status_code == 200:
            print("2")
            soup = BeautifulSoup(response.content, 'html.parser')
            return ' '.join(p.get_text().strip() for p in soup.find_all('p'))
        else:
            print("3")
            return "Failed to retrieve content from URL."
    except Exception as e:
        print("4")
        return f"An error occurred: {e}"

# from langchain.document_loaders import WebBaseLoader

# loader = WebBaseLoader("https://sosoeasyword.com/27/?q=YToxOntzOjEyOiJrZXl3b3JkX3R5cGUiO3M6MzoiYWxsIjt9&bmode=view&idx=17122350&t=board")
# data = loader.load()

# Function to process the user input
def process_user_input(user_input):
    if validators.url(user_input):  # Check if input is a valid URL
        return scrape_text_from_url(user_input)
    # elif user_input.endswith('.pdf'):  # Check if input is a PDF file
    #     return extract_text_from_pdf(user_input)
    else:
        return user_input  # Treat input as plain text
    
def extract_text_from_pdf(pdf_file_path):
    with open(pdf_file_path, 'rb') as file:
        reader = PdfReader(file)
        num_pages = len(reader.pages)
        pdf_text = ''
        for page in reader.pages:
            pdf_text += page.extract_text()
    return pdf_text

# def format_response(text):
#     sentences = sent_tokenize(text)
#     formatted_response = '\n\n'.join(sentences)
#     return formatted_response

# ì›¹ì‚¬ì´íŠ¸ ì œëª©
st.title("Easy Read GeneratorğŸ“–")
st.markdown("â­ï¸Ask Me Anything / Copy & Paste Difficult Text / Copy & Paste URLâ­ï¸")
st.markdown("ğŸŒŸEasy Read Material for EveryoneğŸ˜Œ")

st.image('easyread.jpeg') 

with st.expander('What Is Easy Read?'):
    st.write('â€˜Easy readâ€™ refers to the presentation of text in an accessible, easy to understand format. It is often useful for people with learning disabilities, and may also be beneficial for people with other conditions affecting how they process information. \n\n More Info Here: https://www.learningdisabilities.org.uk/learning-disabilities/a-to-z/e/easy-read')


if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

uploaded_file = st.file_uploader("Choose a PDF file", type="pdf")
if uploaded_file is not None:
    # Save the file locally
    with open("temp_pdf_file.pdf", "wb") as f:
        f.write(uploaded_file.getbuffer())
    pdf_text = extract_text_from_pdf("temp_pdf_file.pdf")


user_input = st.chat_input("Enter text/URL")
if user_input:
    prompt = user_input
elif pdf_text:
    prompt = pdf_text
else:
    prompt = None


if prompt:
     st.session_state.messages.append({"role": "user", "content": prompt})
     with st.chat_message("user"):
        st.markdown(prompt)

     prompt = process_user_input(prompt)

# AIê°€ ë³´ë‚¸ ë‹µë³€ì´ë©´ AI ì•„ì´ì½˜ì´ë‘ LLM ì‹¤í–‰ì‹œì¼œì„œ ë‹µë³€ ë°›ê³  ìŠ¤íŠ¸ë¦¬ë°í•´ì„œ ë³´ì—¬ì£¼ê¸°
     with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        result = agent_executor({"input": prompt})

        for chunk in result["output"].split():
            #full_response += chunk + " "
            full_response += chunk.replace('.', '.\n\n') + " " 
            time.sleep(0.1) 
            message_placeholder.markdown(full_response + "â–Œ") 
        message_placeholder.markdown(full_response) 
        #      full_response += chunk + " "
        #      formatted_response = format_response(full_response)
        #      time.sleep(0.1)
        #      message_placeholder.markdown(formatted_response + "â–Œ")
        # message_placeholder.markdown(formatted_response)
        image_prompt = chain.run(result["output"])
        image_url = DallEAPIWrapper().run(image_prompt)
        st.image(image_url)

     st.session_state.messages.append({"role": "assistant", "content": full_response})





# # ì›¹ì‚¬ì´íŠ¸ì—ì„œ ìœ ì €ì˜ ì¸í’‹ì„ ë°›ê³  ìœ„ì—ì„œ ë§Œë“  AI ì—ì´ì „íŠ¸ ì‹¤í–‰ì‹œì¼œì„œ ë‹µë³€ ë°›ê¸°
# if prompt := st.chat_input("Enter text/URL"):

# # ìœ ì €ê°€ ë³´ë‚¸ ì§ˆë¬¸ì´ë©´ ìœ ì € ì•„ì´ì½˜ê³¼ ì§ˆë¬¸ ë³´ì—¬ì£¼ê¸° 
#     st.session_state.messages.append({"role": "user", "content": prompt})
#     with st.chat_message("user"):
#         st.markdown(prompt)

#     prompt = process_user_input(prompt)

# # AIê°€ ë³´ë‚¸ ë‹µë³€ì´ë©´ AI ì•„ì´ì½˜ì´ë‘ LLM ì‹¤í–‰ì‹œì¼œì„œ ë‹µë³€ ë°›ê³  ìŠ¤íŠ¸ë¦¬ë°í•´ì„œ ë³´ì—¬ì£¼ê¸°
#     with st.chat_message("assistant"):
#         message_placeholder = st.empty()
#         full_response = ""
#         result = agent_executor({"input": prompt})

#         for chunk in result["output"].split():
#             #full_response += chunk + " "
#             full_response += chunk.replace('.', '.\n\n') + " " 
#             time.sleep(0.1) 
#             message_placeholder.markdown(full_response + "â–Œ") 
#         message_placeholder.markdown(full_response) 
#         #      full_response += chunk + " "
#         #      formatted_response = format_response(full_response)
#         #      time.sleep(0.1)
#         #      message_placeholder.markdown(formatted_response + "â–Œ")
#         # message_placeholder.markdown(formatted_response)
#         image_prompt = chain.run(result["output"])
#         image_url = DallEAPIWrapper().run(image_prompt)
#         st.image(image_url)

#     st.session_state.messages.append({"role": "assistant", "content": full_response})